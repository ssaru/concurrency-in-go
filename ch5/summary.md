# 2020-08-16, Concurrency in Go, 209~p220

## 목적
-   5장에서는 단일 프로세스 내에서 동시 작업의 규모를 조정하는 방법을 논의한다
-   둘 이상 프로세스를 처리할 때, 동시성이 어떻게 적용되는지 살펴혼다.

## 에러 전파
-   143페이지에서 "에러 처리"에 대해서 논의했지만, 에러가 **어떠한 모습**이어야 하는지, **크고 복잡한 시스템에서 에러가 어떻게 전달되어야하는지**에 대해서는 논의하지 않았다.

-   많은 개발자들이 에러 전파가 시스템의 흐름에서 부수적이거나 "별개"의 요소라고 생각하는 실수를 범한다.
-   에러는 시스템이 사용자가 명시적으로 또는 암시적으로 요청한 작업을 수행할 수 없는 상태에 들어갔음을 나타낸다. 이 때문에, 에러는 몇가지 중요한 정보를 전달해야한다.

1. 발생한 사건
2. 발생한 장소 및 시점
    -   에러는 호출이 시작된 메소드부터 에러가 인스턴스화된 위치로 끝나는 전체 스택 트레이스가 포함되어야함
3. 사용자 친화적인 메세지
    -   사용자에게 표시되는 메세지는 시스템 및 시스템의 사용자에 맞춰 조정해야함
    -   이때, **시스템**, **시스템 사용자**에 대해 간략하면서도 유의미한 정보만 포함해야함
4. 사용자가 추가적인 정보를 얻을 수 있는 방법
    -   전체 스택 트레이스 등 에러의 전체 정보를 표시하는 로그에 상호 참조될 수 있는 ID를 제공해야한다.

-   이러한 정보 없이 사용자에게 전파되는 에러는 실수이며, 버그이다.

-   모든 에러는 다음 두 가지 범주 중에 하나로 분류할 수 있다.
    1. 버그 (사용자가 시스템에 맞춰 정의하지 않은 에러 또는 "처리되지 않은(raw)에러"; 처리되지 않은 에러는 항상 버그다.)
    2. 알려진 예외적인 경우

# 2020-08-18, Concurrency in Go, 220~p227

## 시간 초과

-   시간 초과는 동작을 이해할 수 있는 시스템을 만드는 여러 요소 가운데 결정적인 요소

-   동시 프로세스가 시간 초과를 지원하기 원하는 이유
    1. 시스템 포화
        -   시스템의 경계에 있는 요청이 오랜 시간 후에 처리되는 것보다는 시간 초과되는 것을 원할 수도 있다.
        -   시간초과를 발생시키는 경우에 대한 몇가지 지침이 있다.
            1. 시간초과되었다고 해도, 요청이 반복될 가능성이 낮음
            2. 요청을 저장하기 위한 메모리, 영속적인 대기열을 저장하기 위한 디스크 공간 등 요청을 저장할 수 있는 리소스 부족
            3. 시간이 지날수록 요청 또는 전송 중인 데이터의 필요성이 줄어듦
    2. 오래된 데이터
        -   데이터가 처리되어야하는 기간보다 오래 걸리는 경우 (사전에 대략적으로 알고있다면 `context.WithDeadline` or `context.WithTimeout`)
    3. 데드락을 막으려는 시도
        -   데드락 문제를 라이브락 문제로 치환하는 방법으로 권장하지 않으나, 시스템을 리부팅해야하는 데드락보다는 라이브락을 유발시켜 복구할 수 있도록 만드는 측면에서 사용할 수 있다.

-   동시 프로세스가 취소될 수 있는 이유
    1. 시간 초과
    2. 사용자 개입
    3. 부모 프로세스의 취소
    4. 복제된 요청

-   언제든지 종료될 수 있는 동시성 코드를 작성할 때, 고려해야할 사항
    -   동시 프로세스가 선점될 수 있는 기간 정의
    -   많은 시간이 걸리는 기능은 자체적으로 선점 가능 보장
    -   이를 위해 고루틴을 작은 조각으로 나눔

-   중복된 메세지를 처리하는 방법
    1. 자식 고루틴이 결과를 보고한 후에는 부모 고루틴이 취소신호를 보낼 가능성이 거의 없도록 설계 (하트비트)
    2. 처음 또는 마지막으로 보고된 결과 수용 (중복을 허용하고 중복된 메세지 중 하나를 수락할지에 대한 선택권을 줌)
    3. 부모 고루틴을 pooling하여 권한 부여(복잡함)

# 2020-09-09, Concurrency in Go, 245~p262

## 속도 제한

-   속도 제한이란, 리소스에 대한 접근을 단위 시간당 특정 횟수로 제한하는 것을 말한다.
    -   서비스에 속도 제한을 적용하는 이유는 아래와 같다.
        1. 시스템에 대한 전체적인 공격을 차단한다.
        2. 분산 시스템에서 특정 사용자가 리소스를 과다 사용함으로 인하여 다른 사용자의 서비스 퀄리티를 저하하는 경우, 최소한의 서비스 퀄리티를 보장하기 위해서
    -   분산 시스템과 같은 복잡한 시스템에서 속도 제한을 하지않는다면, 작은 영향이 시스템 전체로 파급될 수 있으며, 극단적으로 시스템의 중단을 야기할 수 있다.
    -   속도 제한은 시스템이 사저넹 조사한 경계를 벗어나는 것을 막음으로써, 시스템의 성능과 안정성을 판단할 수 있도록 해준다.

-   속도 제한은 **토큰 버킷**이라는 알고리즘을 통해서 달성할 수 있다.
    1. 토큰 버킷은 한번에 d개의 접근 토큰을 보유할 수 있으며, 이를 토큰 깊이라고 부른다.
    2. 리소스에 접근할 때마다, 이 토큰을 하나 제거한다.
    3. 토큰을 모두 사용하면, 토큰이 채워질때까지 요청을 대기열에 넣어두던가, 거부한다.
    4. 토큰은 주어진 주기에 맞춰 다시 생성된다. 이렇게 재생성되는 주기를 속도로 정의된다.

- 예제는 아래와 같이 진행됩니다.
    1. 단일 리소스에 대한 속도 제한
    2. 여러 속도 제한 정책을 다루는 방법
    3. 여러 리소스에 대해 속도 제한을 하는 방법
